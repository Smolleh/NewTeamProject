
{% extends "base.html" %}
{%block content %}
    
    <h1>Privacy Policy</h1>

    <section>
        <h2> Introduction </h2>
        <p>This document identifies the ethical and legal considerations for the project of an educational prototype of an AI failures museum. The system encourages reflection and learning by presenting examples of failures in AI systems. These failures could include ethical or legal implications and it’s important to assess the privacy, accessibility, security and misinformation risk issue. The following describes these considerations in more detail and how we have managed them during the development of the system.</p>
    
        <h2> Privacy <h2> 
        <h3>  Data minimization</h3>
        <p>In terms in privacy issues, we need to ensure we only collect the minimal data we require for our system to function. Therefore, this means collecting factual information and avoiding gathering too much detail about personal information from visitors for example. Only minimal data is collected for analytics to try and provide a service for users which does not exploit their personal data. </p>
        <h3>Public vs private infomation</h3>
        <p>User quiz results being made public</p>
    
        <h2> Privacy : Data minimization</h2>
        <h2>Accessibility</h2>
        <p>Interface designed clearly. Furthermore, we aim to make our system as accessible for users as possible by designing intuitive interfaces in the web-application for users to be able to navigate through the exhibits with ease. Issues with the accessibility of our system would arise if text is too small, there are no clear instructions on how to view the different exhibits or if error messages are unclear.</p>
        <h2>Navigation structure simple</h2>
        <p>The menus in our web-application need to be simple and not overwhelming to navigate. Complex menus could create a challenge for users with minimal digital experience to fully utilize the system.</p>
        <h3>Layout responsive across different screen sizes</h3>
        <p>The web-application we create must be compatible for devices with different screen sizes such as mobile phones or tablets. This could result in an issue if our system only functions properly on laptops because it would exclude users from accessing the system who are trying to connect from a different device. 	</p>
            

    
        <h2> Security :  </h2>
        <h3>Authentication to restrict access to system features</h3>
        <p>Moreover, there should be different levels of access to the system. For instance, there needs to be controls over who can do what on the system such as adding an exhibit or viewing the exhibits. If the authentication of the system is not particularly strong then this could result in unauthorized users gaining administrative roles and this would be an issue because changes could be made to the system which shouldn’t be.</p>
        <h3>Role-based access control for admin and general users</h3>
        <p>In addition, having different permission levels in the system would ensure that general users can’t modify the exhibits while admin users will have this ability. Therefore, a security issue could arise here if the permissions are not configured accurately and allow privileges to be granted to users who shouldn’t have it. </p>
        <h3>No storage of sensitive personal data</h3>
        <p>Avoid collection of financial information + ensuring data doesn’t become identifying when combine (e.g., quiz patterns revealing individual users)
        </p>
    
        <h2> Misinformation Risk :  </h2>
        <h2>Users interpreting exhibit content as authoritative</h2>
        <p>Finally, there are a couple of risks that could arise from this system in terms of misinformation. For example, users could treat the exhibits of AI failures as the definitive source and come to decisions or conclusions based on partially incomplete data. This becomes an issue if the cases of AI failures are simplified or not represented accurately from their original source.  </p>
        <h2>Clear-labelling of system as educational tool and not decision-making tool</h2>
        <h2>Context for each AI failure to explain factors</h2>
        <p>Each exhibit should provide sufficient context to ensure that users don’t reach conclusions about instances which are oversimplified. For example, “AI is always a danger” or “this business was ignorant” as without the required context, the causes of these AI failures may be misunderstood and this could be an issue. </p>
        <h2> Quiz framed as learning aids not formal assessments </h2>
        <p> It’s also important that the quizzes for the exhibits are clearly framed as learning aids and not formal tests. Issues could become apparent here if users mistake the scores for grades and therefore competitive elements leading to cheating. This takes away from the actual purpose of the system which is to raise awareness to more people of how AI is impacting our world and diminishes the learning aspect.  </p></p>
    
    
    
    
    

    </section>
    

    {% endblock %}






